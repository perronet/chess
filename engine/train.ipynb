{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import setup\n",
    "import parse\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.activations import relu,linear\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(setup.DATASET, nrows=setup.N_ROWS, dtype={\"Fen\": np.string_, \"Evaluation\": np.string_})\n",
    "if setup.N_ROWS >= 469187 + 1:\n",
    "    df = df.drop(469187) # Corrupted string in this dataset\n",
    "    df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each board is converted from FEN to the following vectorized representation:\n",
    "\n",
    "| **# Features** | **Type**                 | **Value range** |\n",
    "|----------------|--------------------------|-----------------|\n",
    "| 64             | Piece                    | -6 - +6           |\n",
    "| 1              | Side to move             | 0 / 1          |\n",
    "| 4              | Castling rights          | 0 / 1          |\n",
    "<!-- | 1              | En passant target square | 0-16            | -->\n",
    "<!-- | 1              | Half-move clock          | 0-50            | -->\n",
    "\n",
    "This results in a vector of 70 features. We discard the move counter and half-move clock provided in the last field in the FEN format. This means that we will have to take care of draws manually.\n",
    "\n",
    "Un-normalized scores can be as high/low as 15k. Each score is converted to a range of -1 - 1 using a sigmoid to reflect the likelyhood of winning.\n",
    "\n",
    "| **Output type**                 | **Value range** |\n",
    "|----------------|--------------------------|\n",
    "| Score             | 0 - 1                    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f\"f_{str(x)}\" for x in range(1, setup.N_FEATURES+1)]\n",
    "df_vectorized = pd.DataFrame(df[\"FEN\"].apply(lambda fen_str: parse.fen_to_vector(fen_str)).to_list(), columns=features)\n",
    "df_vectorized[\"label\"] = df[\"Evaluation\"].apply(lambda score: parse.normalize_stockfish_eval(score))\n",
    "df_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "assert df_vectorized[df_vectorized.isnull().values].empty\n",
    "# Check shape (+1 if for the label)\n",
    "assert df_vectorized.shape == (setup.N_ROWS, setup.N_FEATURES + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import setup\n",
    "\n",
    "X = df_vectorized[features]\n",
    "y = df_vectorized[\"label\"]\n",
    "\n",
    "# normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "# normalizer.adapt(X)\n",
    "'''\n",
    "TODOs\n",
    "* Try normalizing and check if we are doing it properly (axis=-1??)\n",
    "* Try elu and leakyrelu\n",
    "* Try SGD\n",
    "'''\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        # normalizer,\n",
    "        Input(shape=(setup.N_FEATURES,)),\n",
    "        Dense(3048, activation=setup.HIDDEN_ACTIVATION, kernel_regularizer=tf.keras.regularizers.l2(setup.REGULARIZATION_RATE)),\n",
    "        Dense(3048, activation=setup.HIDDEN_ACTIVATION, kernel_regularizer=tf.keras.regularizers.l2(setup.REGULARIZATION_RATE)),\n",
    "        Dense(3048, activation=setup.HIDDEN_ACTIVATION, kernel_regularizer=tf.keras.regularizers.l2(setup.REGULARIZATION_RATE)),\n",
    "        Dense(1024, activation=setup.HIDDEN_ACTIVATION, kernel_regularizer=tf.keras.regularizers.l2(setup.REGULARIZATION_RATE)),\n",
    "        Dense(1, activation=setup.OUTPUT_ACTIVATION),\n",
    "    ]\n",
    ")\n",
    "model.compile(\n",
    "    loss=MeanSquaredError(),\n",
    "    optimizer=Adam(learning_rate=setup.LEARNING_RATE),\n",
    "    # optimizer=SGD(learning_rate=setup.LEARNING_RATE, nesterov=True, momentum=0.7),\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import setup\n",
    "\n",
    "model.fit(X, y, epochs=setup.EPOCHS, batch_size=setup.BATCH_SIZE, callbacks=[\n",
    "    tf.keras.callbacks.TerminateOnNaN(), \n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=setup.PATIENCE)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/loss_new\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test error on cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the next N_ROWS as cross-validation\n",
    "# TODO use train_test_split!\n",
    "df_cv = pd.read_csv(setup.DATASET, skiprows=setup.N_ROWS, nrows=setup.N_ROWS, names=[\"FEN\", \"Evaluation\"], header=None)\n",
    "df_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f\"f_{str(x)}\" for x in range(1, setup.N_FEATURES+1)]\n",
    "df_cv_vectorized = pd.DataFrame(df_cv[\"FEN\"].apply(lambda fen_str: parse.fen_to_vector(fen_str)).to_list(), columns=features)\n",
    "df_cv_vectorized[\"label\"] = df_cv[\"Evaluation\"].apply(lambda score: parse.normalize_stockfish_eval(score))\n",
    "df_cv_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_vectorized[\"prediction\"] = model.predict(df_cv_vectorized[features])\n",
    "df_cv_vectorized[\"error\"] = (df_cv_vectorized[\"prediction\"] - df_cv_vectorized[\"label\"])**2\n",
    "df_cv_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_vectorized[\"error\"].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
